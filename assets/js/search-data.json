{
  
    
        "post0": {
            "title": "COVID-19 - Overview",
            "content": "This page was last built on 20.06.21 02:29:23 . Colors: If the last reported cases are &lt; 25% of the maximum, the data is shown in green. Else, if the last cases are &gt; 75% of the maximum, the data is shown in red. Else, grey. . Axes: The data is shown on a normalized y-axis. This means that the actual numbers between countries can be very different and should not be compared. On the x-axis, the data is shown from the day of the 100th positive case until today. . Preprocessing: The number of new cases per day is averaged using a 10-day rolling window. Countries are included if they have at least 1000 cases and at least 100 deaths. Countries are sorted by total number of cases. . Data: The data is pulled from the COVID-19 Data Repository by Johns Hopkins CSSE .",
            "url": "https://caglorithm.github.io/notebooks/covid-dashboard-v2/",
            "relUrl": "/covid-dashboard-v2/",
            "date": " • Nov 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "COVID-19 Lo-Fi wave tunes",
            "content": "This page was last built on 01.11.20 15:36:35 . Sonification: A sine wave is frequency modulated with the number of new daily cases. The amplitude is modulated with the daily change of new daily cases. . Colors: If the last reported cases are &lt; 33% of the maximum, the data is shown in green. Else, if the last cases are &gt; 66% of the maximum, the data is shown in red. Else, grey. . Axes: The data is shown on a normalized y-axis. This means that the actual numbers between countries can be very different and should not be compared. On the x-axis, the data is shown from the day of the 100th positive case until today. . Preprocessing: The number of new cases per day is averaged using a 7-day rolling window. Countries are included if they have at least 100000 cases and at least 1000 deaths. Countries are sorted by total number of cases. . Data: The data is pulled from the COVID-19 Data Repository by Johns Hopkins CSSE . Disclaimer: I am not an expert on Covid. There might be glitches or mistakes in my data processing. Please wear a mask when necessary, apparently they do work. I hope you&#39;ll all stay healthy. . Waveforms . Sonified output . Please dial down the volume. The following is not exactly nice to listen to: . US . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/US.mp3 . Brazil . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Brazil.mp3 . India . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/India.mp3 . Mexico . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Mexico.mp3 . United Kingdom . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/United Kingdom.mp3 . Italy . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Italy.mp3 . France . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/France.mp3 . Spain . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Spain.mp3 . Peru . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Peru.mp3 . Iran . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Iran.mp3 . Colombia . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Colombia.mp3 . Argentina . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Argentina.mp3 . Russia . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Russia.mp3 . South Africa . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/South Africa.mp3 . Chile . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Chile.mp3 . Indonesia . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Indonesia.mp3 . Ecuador . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Ecuador.mp3 . Belgium . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Belgium.mp3 . Iraq . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Iraq.mp3 . Germany . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Germany.mp3 . Canada . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Canada.mp3 . Turkey . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Turkey.mp3 . Bolivia . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Bolivia.mp3 . Netherlands . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Netherlands.mp3 . Philippines . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Philippines.mp3 . Ukraine . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Ukraine.mp3 . Pakistan . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Pakistan.mp3 . Romania . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Romania.mp3 . Egypt . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Egypt.mp3 . Sweden . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Sweden.mp3 . Bangladesh . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Bangladesh.mp3 . Saudi Arabia . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Saudi Arabia.mp3 . Poland . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Poland.mp3 . Guatemala . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Guatemala.mp3 . Morocco . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Morocco.mp3 . Czechia . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Czechia.mp3 . Panama . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Panama.mp3 . Israel . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Israel.mp3 . Portugal . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Portugal.mp3 . Dominican Republic . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Dominican Republic.mp3 . Switzerland . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Switzerland.mp3 . Kazakhstan . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Kazakhstan.mp3 . Costa Rica . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Costa Rica.mp3 . Oman . https://github.com/caglorithm/notebooks/raw/master/_notebooks/data/covid_mp3/Oman.mp3 .",
            "url": "https://caglorithm.github.io/notebooks/covid-radio/",
            "relUrl": "/covid-radio/",
            "date": " • Oct 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Parsing Q",
            "content": "QAnon, a far-right global conspiracy theory is one of the weirdest stories the internet (or 4chan/8chan/8kun in particular) has brought about. You&#39;re probably heard enough about the insane stories and its crazy supporters, so I won&#39;t go into any details here. What I&#39;m interested in is what many of us would like to know: Who is Q? Is it one person or many? Is it a delusional psychopath or someone staging the biggest scam in the history of the internet? Is it an ARG? Or is it all made up by the a US pig farmer who lives in the Philippines, called Jim Watkins? Does the NSA know who he is? . What we know: . Q posts on 8kun and identifies using a tripcode system. | 8kun&#39;s admin is Ron Watkins, Jim Watkins&#39; son. | All posts are gathered on an aggregator called Qmap dot pub, which is tied to Watkins and is now offline. | . Someone scraped all of Q&#39;s posts from Qmap days before it was taken offline. The entire dataset is provided here for anyone to download and to play with. What follows is a basic and preliminary analysis of the aggregated posts of Q. . Parse data . The dataset . This is what the data set looks like: . Unnamed: 0 id tripcode t title text minute hour month year . 0 0 | 950 | !UW.yye1fxo | 2018-03-15 23:44:40 | Trust Mike Pompeo (Kansas) | n n Anonymous nThu Mar 15 2018 23:43:08 GMT+0... | 44 | 23 | 3 | 2018 | . 1 1 | 3298 | !!mG7VJxZNCI | 2019-03-28 21:02:23 | LOVE OF COUNTRY! #FLAGSOUT | https://twitter.com/tysoneberly/status/1111370... | 2 | 21 | 3 | 2019 | . 2 2 | 553 | !UW.yye1fxo | 2018-01-19 05:04:38 | Military Intel &amp; State Secrets | The TELL.How can we listen in, track, and moni... | 4 | 5 | 1 | 2018 | . 3 3 | 3714 | !!Hs1Jq13jV6 | 2019-12-17 21:23:02 | Flynn FISA Was Illegal and Manipulated by the FBI | https://www.fisc.uscourts.gov/sites/default/fi... | 23 | 21 | 12 | 2019 | . 4 4 | 3108 | !!mG7VJxZNCI | 2019-03-18 02:42:20 | Patriots in Control of Twitter? | nHello, Jack.png n | 42 | 2 | 3 | 2019 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 8956 8956 | 2119 | !!mG7VJxZNCI | 2018-09-08 18:33:44 | Home of The Brave | There was a time when our children stood at at... | 33 | 18 | 9 | 2018 | . 8957 8957 | 2862 | !!mG7VJxZNCI | 2019-02-22 16:04:36 | Accurate Memes of Bill and Loretta&#39;s Infamous ... | nD0BB65WWwAEC8wP.jpg nD0BJNbMX4AEiDfk.jpg nD0... | 4 | 16 | 2 | 2019 | . 8958 8958 | 502 | !UW.yye1fxo | 2018-01-08 03:44:09 | DEFCON 1 Stringer/Marker | Original [15] minDEFCON [1] CONF Revised [1] m... | 44 | 3 | 1 | 2018 | . 8959 8959 | 2768 | !!mG7VJxZNCI | 2019-02-17 22:04:54 | Jussie Smollett False Flag Linked to Sen. Kama... | nDzlpRPbVsAEYuyS.jpg-large.jpg n | 4 | 22 | 2 | 2019 | . 8960 8960 | 318 | !ITPb.qbhqo | 2017-12-09 19:01:00 | Chester Bennington and Chris Cornell | n n Anonymous nSat Dec 09 2017 18:55:39 GMT+0... | 1 | 19 | 12 | 2017 | . 8961 rows × 10 columns . Analysis . These are the tripcodes that Q has used in the past: . !UW.yye1fxo !!mG7VJxZNCI !!Hs1Jq13jV6 !4pRcUA0lBE !xowAT4Z3VQ !CbboFOtcZs !ITPb.qbhqo !A6yxsPKia. !2jsTvXXmXs . Q has been getting lazy . At what time of the day does Q post? .",
            "url": "https://caglorithm.github.io/notebooks/parsing-q/",
            "relUrl": "/parsing-q/",
            "date": " • Oct 6, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "COVID-19 - Dashboard overview",
            "content": "This page was last built on 20.06.21 02:24:20 . Colors: If the last reported cases are &lt; 25% of the maximum, the data is shown in green. Else, if the last cases are &gt; 75% of the maximum, the data is shown in red. Else, grey. . Axes: The data is shown on a normalized y-axis. This means that the actual numbers between countries can be very different and should not be compared. On the x-axis, the data is shown from the day of the 100th positive case until today. . Preprocessing: The number of new cases per day is averaged using a 10-day rolling window. Countries are included if they have at least 1000 cases and at least 100 deaths. Countries are sorted by total number of cases. . Data: The data is pulled from the COVID-19 Data Repository by Johns Hopkins CSSE . Versions: . Color neural version for folks who prefer other colors than red and green | Alphabetically sorted | Larger version with less filtering and many more countries | Large color neutral | . Countries sorted by total cases . Large overview .",
            "url": "https://caglorithm.github.io/notebooks/covid-dashboard/",
            "relUrl": "/covid-dashboard/",
            "date": " • May 4, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "COVID-19 - How long until herd immunity?",
            "content": "This page was last built on 20.06.21 02:20:04 . There seems to be only two realistic scenarios how the Corona pandemic could end. . In the first scenario, we find a vaccine and reach wide-spread immunity on a global scale. This could take one year or maybe two. Looking at the second option, this could be the better strategy: . In the second scenario, we reach herd immunity and most of the population produces antibodies for the Corona virus. The threshold for herd immunity for the Corona virus is assumed to be around 60% of the global population. . Disclaimer: Please note that &quot;confirmed cases&quot; are known to grossly underestimate the number of people with antibodies. Recent numbers (23.04.2020) suggested that up to 13.9% of NYC citizens could have antibodies although the number of confirmed cases is at around 5% of the population. In this notebook, we also plot the results for when 50% or 90% of cases remain undetected. . Infected population . To estimate how much the pandemic has progressed, we calculate the percentage of the population that was already infected. Since it is often assumed that many, if not most, of the cases in many countries are not detected, we also plot the number of estimated undetected cases, assuming that these are between 50% and 90% of the total cases, either because they remain asymptomatic or because they simply not tested for. . Extrapolation . We can estimate the time it takes to reach a 60% infection of the population by extrapolating the already observed cases into the future. This estimation is model-free: we simply take the 30 day average of the past confirmed new cases and assume that the infection rate (or rather the case confirmation rate) stays constant. Then, we can easily calculate how long it would take for each country to reach 60% of its population. . As of 25.04.2020, this number for many, if not all, countries is absurdly high. This can be due to do with the fact the outbreak hasn&#39;t really started in most places yet since only a tiny amount of the population was infected or that testing capabilities are still very insufficient in many places. This number will change as the pandemic progresses and as we get a better estimation of the actual infection rate. . Combined view . Baseline measurements . Here we show the case rate for each country and highlight the last 30 days of confirmed cases that were used as a baseline to project the case rate into the future. . Afghanistan . Albania . Algeria . Angola . Argentina . Armenia . Australia . Austria . Azerbaijan . Bahrain . Bangladesh . Belarus . Belgium . Belize . Benin . Bolivia . Bosnia and Herzegovina . Botswana . Brazil . Bulgaria . Burkina Faso . Cambodia . Cameroon . Canada . Chad . Chile . China . Colombia . Comoros . Costa Rica . Croatia . Cuba . Cyprus . Czechia . Denmark . Djibouti . Dominican Republic . Ecuador . Egypt . El Salvador . Equatorial Guinea . Estonia . Ethiopia . Finland . France . Gabon . Georgia . Germany . Ghana . Greece . Guatemala . Guinea . Guyana . Haiti . Honduras . Hong Kong . Hungary . India . Indonesia . Iran . Iraq . Ireland . Israel . Italy . Jamaica . Japan . Jordan . Kazakhstan . Kenya . Kuwait . Kyrgyzstan . Latvia . Lebanon . Lesotho . Libya . Lithuania . Luxembourg . Madagascar . Malawi . Malaysia . Maldives . Mali . Malta . Mauritania . Mexico . Moldova . Mongolia . Morocco . Mozambique . Namibia . Nepal . Netherlands . Nicaragua . Niger . Nigeria . Norway . Oman . Pakistan . Panama . Papua New Guinea . Paraguay . Peru . Philippines . Poland . Portugal . Qatar . Romania . Russia . Rwanda . Saudi Arabia . Senegal . Serbia . Slovakia . Slovenia . Somalia . South Africa . South Korea . South Sudan . Spain . Sri Lanka . Sudan . Suriname . Sweden . Switzerland . Syria . Thailand . Togo . Trinidad and Tobago . Tunisia . Turkey . US . Uganda . Ukraine . United Arab Emirates . United Kingdom . Uruguay . Uzbekistan . Venezuela . Yemen . Zambia . Zimbabwe .",
            "url": "https://caglorithm.github.io/notebooks/covid-herd-immunity/",
            "relUrl": "/covid-herd-immunity/",
            "date": " • Apr 25, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Tracking German election polling surveys",
            "content": "The data for this script is pulled from https://www.wahlrecht.de/umfragen. Below the code, you can find the output figures. . This page was last built on 20.06.21 02:19:25 . import pandas as pd import matplotlib.pyplot as plt import datetime import matplotlib.dates as mdates from scipy.ndimage import gaussian_filter1d table_urls = [&quot;https://www.wahlrecht.de/umfragen/allensbach.htm&quot;, &quot;https://www.wahlrecht.de/umfragen/emnid.htm&quot;, &quot;https://www.wahlrecht.de/umfragen/forsa.htm&quot;, &quot;https://www.wahlrecht.de/umfragen/politbarometer.htm&quot;, &quot;https://www.wahlrecht.de/umfragen/gms.htm&quot;, &quot;https://www.wahlrecht.de/umfragen/dimap.htm&quot;, &quot;https://www.wahlrecht.de/umfragen/yougov.htm&quot;, #&quot;https://www.wahlrecht.de/umfragen/insa.htm&quot; # broken data ] names = [&quot;Allensbach&quot;, &quot;Kantar&quot;, &quot;Forsa&quot; &quot;Forsch’gr. Wahlen&quot;, &quot;GMS&quot;, &quot;Infratest&quot;, &quot;dimap&quot;, &quot;Yougov&quot;, &quot;INSA&quot;] # get the election results election_results = pd.read_html(&quot;https://www.wahlrecht.de/umfragen/&quot;)[1] election_results[&quot;percent&quot;] = election_results[&quot;Bundes-tagswahl&quot;].iloc[1:].str.replace(&#39;,&#39;, &#39;.&#39;).str.rstrip(&#39;%&#39;).astype(&#39;float&#39;) election_results = election_results.set_index(&quot;Institut&quot;) # get polling results party_to_watch = &quot;AfD&quot; def get_party_results(party_to_watch = &quot;AfD&quot;): print(f&quot;- {party_to_watch} -&quot;) plt.figure(figsize=(5, 3), dpi=300) for i, table_url in enumerate(table_urls): # hotfix for linke table entry party_name = &quot;LINKE&quot; if party_to_watch == &quot;DIE LINKE&quot; else party_to_watch print(f&quot;Getting data from {names[i]} ...&quot;) # magic function to get tables from a website, &lt;3 df = pd.read_html(table_url)[1] # cut last 4 lines which are trash df = df.iloc[:-4] df = df.replace(&quot;–&quot;) # convert to datetime df[&quot;Datetime&quot;] = pd.to_datetime(df[&quot;Datum&quot;], format=&quot;%d.%m.%Y&quot;) if &quot;Datum&quot; in df.columns else pd.to_datetime(df[&quot;Unnamed: 0&quot;], format=&quot;%d.%m.%Y&quot;) # get rid of trash df = df.drop(columns=[&quot;Unnamed: 0&quot;, &quot;Unnamed: 1&quot;]) # list of parties parties = df.columns[:6] for party in parties: df[party] = df[party].str.replace(&#39;,&#39;, &#39;.&#39;).str.rstrip(&#39;%&#39;).astype(&#39;float&#39;) smoothed = gaussian_filter1d(df[party_name], 1) print(f&quot; tLast value: {df[party_name].iloc[0]}%&quot;) print(f&quot; tLast datapoint: {df[&#39;Datetime&#39;].iloc[0].date()}&quot;) plt.plot(df[&quot;Datetime&quot;], smoothed,label=names[i], c=&quot;C&quot; + str(i)) plt.plot(df[&quot;Datetime&quot;], df[party_name], ls=&#39;:&#39;, lw=1, c=&quot;C&quot; + str(i)) from_weeks = 24 * 4 to_weeks = 4 # add line that marks results from last elections plt.hlines(election_results.loc[party_to_watch, &quot;percent&quot;], datetime.datetime.now() - datetime.timedelta(weeks=from_weeks), datetime.datetime.now() + datetime.timedelta(weeks=to_weeks), color=&#39;k&#39;, ls=&#39;--&#39;, label=f&#39;{party_to_watch} Bundestagswahl 2017&#39;) # adjust plot settings plt.title(f&quot;Watch the {party_to_watch} go pew&quot;) plt.xlim([datetime.datetime.now() - datetime.timedelta(weeks=from_weeks), datetime.datetime.now() + datetime.timedelta(weeks=to_weeks)]) myFmt = mdates.DateFormatter(&quot;%d.%m.%Y&quot;) plt.gca().xaxis.set_major_formatter(myFmt) plt.grid() plt.legend(fontsize=8, bbox_to_anchor=(1.0, 1.0)) plt.ylabel(&quot;Polling result [%]&quot;) plt.setp(plt.gca().get_xticklabels()[::2], visible=False) plt.xticks(rotation=45) plt.savefig(f&quot;../images/icon_{party_to_watch.replace(&#39;/&#39;, &#39;_&#39;).replace(&#39; &#39; , &#39;_&#39;).lower()}.png&quot;); plt.show() . - AfD - Getting data from Allensbach ... Last value: 9.0% Last datapoint: 2021-06-16 Getting data from Kantar ... Last value: 10.0% Last datapoint: 2021-06-18 Getting data from ForsaForsch’gr. Wahlen ... Last value: 9.0% Last datapoint: 2021-06-16 Getting data from GMS ... Last value: 11.0% Last datapoint: 2021-06-10 Getting data from Infratest ... Last value: 11.0% Last datapoint: 2021-05-17 Getting data from dimap ... Last value: 12.0% Last datapoint: 2021-06-10 Getting data from Yougov ... Last value: 11.0% Last datapoint: 2021-05-27 . - CDU/CSU - Getting data from Allensbach ... Last value: 29.5% Last datapoint: 2021-06-16 Getting data from Kantar ... Last value: 27.0% Last datapoint: 2021-06-18 Getting data from ForsaForsch’gr. Wahlen ... Last value: 28.0% Last datapoint: 2021-06-16 Getting data from GMS ... Last value: 28.0% Last datapoint: 2021-06-10 Getting data from Infratest ... Last value: 26.0% Last datapoint: 2021-05-17 Getting data from dimap ... Last value: 28.0% Last datapoint: 2021-06-10 Getting data from Yougov ... Last value: 26.0% Last datapoint: 2021-05-27 . - SPD - Getting data from Allensbach ... Last value: 17.0% Last datapoint: 2021-06-16 Getting data from Kantar ... Last value: 17.0% Last datapoint: 2021-06-18 Getting data from ForsaForsch’gr. Wahlen ... Last value: 14.0% Last datapoint: 2021-06-16 Getting data from GMS ... Last value: 15.0% Last datapoint: 2021-06-10 Getting data from Infratest ... Last value: 15.0% Last datapoint: 2021-05-17 Getting data from dimap ... Last value: 14.0% Last datapoint: 2021-06-10 Getting data from Yougov ... Last value: 15.0% Last datapoint: 2021-05-27 . - GRÜNE - Getting data from Allensbach ... Last value: 21.5% Last datapoint: 2021-06-16 Getting data from Kantar ... Last value: 20.0% Last datapoint: 2021-06-18 Getting data from ForsaForsch’gr. Wahlen ... Last value: 21.0% Last datapoint: 2021-06-16 Getting data from GMS ... Last value: 22.0% Last datapoint: 2021-06-10 Getting data from Infratest ... Last value: 24.0% Last datapoint: 2021-05-17 Getting data from dimap ... Last value: 20.0% Last datapoint: 2021-06-10 Getting data from Yougov ... Last value: 22.0% Last datapoint: 2021-05-27 . - FDP - Getting data from Allensbach ... Last value: 11.0% Last datapoint: 2021-06-16 Getting data from Kantar ... Last value: 12.0% Last datapoint: 2021-06-18 Getting data from ForsaForsch’gr. Wahlen ... Last value: 14.0% Last datapoint: 2021-06-16 Getting data from GMS ... Last value: 10.0% Last datapoint: 2021-06-10 Getting data from Infratest ... Last value: 11.0% Last datapoint: 2021-05-17 Getting data from dimap ... Last value: 12.0% Last datapoint: 2021-06-10 Getting data from Yougov ... Last value: 12.0% Last datapoint: 2021-05-27 . - DIE LINKE - Getting data from Allensbach ... Last value: 7.0% Last datapoint: 2021-06-16 Getting data from Kantar ... Last value: 7.0% Last datapoint: 2021-06-18 Getting data from ForsaForsch’gr. Wahlen ... Last value: 7.0% Last datapoint: 2021-06-16 Getting data from GMS ... Last value: 7.0% Last datapoint: 2021-06-10 Getting data from Infratest ... Last value: 7.0% Last datapoint: 2021-05-17 Getting data from dimap ... Last value: 7.0% Last datapoint: 2021-06-10 Getting data from Yougov ... Last value: 7.0% Last datapoint: 2021-05-27 . - AfD - Getting data from Allensbach ... Last value: 9.0% Last datapoint: 2021-06-16 Getting data from Kantar ... Last value: 10.0% Last datapoint: 2021-06-18 Getting data from ForsaForsch’gr. Wahlen ... Last value: 9.0% Last datapoint: 2021-06-16 Getting data from GMS ... Last value: 11.0% Last datapoint: 2021-06-10 Getting data from Infratest ... Last value: 11.0% Last datapoint: 2021-05-17 Getting data from dimap ... Last value: 12.0% Last datapoint: 2021-06-10 Getting data from Yougov ... Last value: 11.0% Last datapoint: 2021-05-27 .",
            "url": "https://caglorithm.github.io/notebooks/polling-data/",
            "relUrl": "/polling-data/",
            "date": " • Apr 22, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Waiting for R2...",
            "content": "Every academic knows that quite some time can pass from submission of a paper to a journal until acceptance and eventually publication. Whether it&#39;s the tedious communications with the Editors about the font size of a figure label or the questions in suspiciously minute detail from Reviewer 2. . Past publications in a journal can be indicative for how long your own submission process could take. For this case study, I have looked at how long it takes for papers in the field of Computational Neuroscience (which is the field I am working in) to be accepted at Nature Neuroscience, one of the most prestigious neuroscience journals out there. . To get this information, we can crawl publicly available data from the Nature website. Every article&#39;s page has the time of submission, acceptance and publication that we can gather to compute an average. An example is shown below. . . We use the wonderful functions provided in requests_html to scrape the data. The script below goes through all search results from the Nature website, filtered by a specific subject, in this case it is &quot;computational-neuroscience&quot;. We get a list of all articles by filtering the relevant elements we want to iterate through using the function base_html.html.find(). Then, we can easily get the relevant elements of the search results (the title and the html links to each article for example) using the attributes .text and .links. . #hide_output from requests_html import HTMLSession session = HTMLSession() data = pd.DataFrame(columns=[&#39;journal&#39;, &#39;url&#39;, &#39;title&#39;, &#39;received&#39;, &#39;accepted&#39;, &#39;published&#39;, &#39;timeForAcceptance&#39;, &#39;timeForPublishing&#39;]) for page_nr in range(1, 5): base_url = &quot;https://www.nature.com/search?order=relevance&amp;journal=neuro&amp;subject=computational-neuroscience&amp;article_type=research&amp;page=&quot; base_url += str(page_nr) base_html = session.get(base_url) articles_journal = base_html.html.find(&#39;div.grid.grid-7.mq640-grid-12.mt10&#39;) articles = base_html.html.find(&quot;a[href*=articles]&quot;) for ai, a in enumerate(articles_journal): filter_journal = &#39;Nature Neuroscience&#39; if filter_journal in a.text: print(&quot; - - - - - - - - &quot;) print(&#39;Article nr {} on page {} in Journal {}&#39;.format(ai, page_nr, filter_journal)) article_title = articles[ai].text print(&quot; &quot;{} &quot;&quot;.format(article_title)) article_suburl = list(articles[ai].links)[0] article_url = &quot;https://www.nature.com{}&quot;.format(article_suburl) print(&quot;Getting {}&quot;.format(article_url)) article_html = session.get(article_url) dates = article_html.html.find(&quot;time&quot;) print(&#39;&gt; Received: &#39;, dates[1].attrs[&#39;datetime&#39;]) print(&#39;&gt; Accepted: &#39;, dates[2].attrs[&#39;datetime&#39;]) print(&#39;&gt; Published: &#39;, dates[3].attrs[&#39;datetime&#39;]) received_date = parser.parse(dates[1].attrs[&#39;datetime&#39;]) accepted_date = parser.parse(dates[2].attrs[&#39;datetime&#39;]) published_date = parser.parse(dates[3].attrs[&#39;datetime&#39;]) timeForAcceptance = accepted_date - received_date timeForPublishing = published_date - received_date print(timeForAcceptance, &#39;between&#39;,received_date, &#39;and&#39;, accepted_date) data = data.append({&#39;journal&#39; : filter_journal, &#39;url&#39; : article_suburl, &#39;title&#39; : article_title, &#39;received&#39; : received_date, &#39;accepted&#39; : accepted_date, &#39;published&#39; : published_date, &#39;timeForAcceptance&#39; : timeForAcceptance, &#39;timeForPublishing&#39; : timeForPublishing}, ignore_index = True) . Let&#39;s have a look at the aggregated Dataframe: . data . journal url title received accepted published timeForAcceptance timeForPublishing . 0 Nature Neuroscience | /articles/s41593-020-00753-w | Strong inhibitory signaling underlies stable t... | 2020-02-17 | 2020-11-05 | 2020-12-07 | 262 days | 294 days | . 1 Nature Neuroscience | /articles/s41593-020-00744-x | Parameterizing neural power spectra into perio... | 2019-05-31 | 2020-10-20 | 2020-11-23 | 508 days | 542 days | . 2 Nature Neuroscience | /articles/s41593-020-00733-0 | Modeling behaviorally relevant neural dynamics... | 2019-09-04 | 2020-10-02 | 2020-11-09 | 394 days | 432 days | . 3 Nature Neuroscience | /articles/s41593-020-00732-1 | A cerebello-olivary signal for negative predic... | 2019-11-25 | 2020-10-02 | 2020-11-09 | 312 days | 350 days | . 4 Nature Neuroscience | /articles/s41593-020-00719-y | Edge-centric functional network representation... | 2019-09-09 | 2020-09-03 | 2020-10-19 | 360 days | 406 days | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 194 Nature Neuroscience | /articles/nn.2797 | Reversible large-scale modification of cortica... | 2011-01-12 | 2011-03-04 | 2011-04-17 | 51 days | 95 days | . 195 Nature Neuroscience | /articles/nn.2904 | Differential roles of human striatum and amygd... | 2011-04-12 | 2011-07-07 | 2011-09-11 | 86 days | 152 days | . 196 Nature Neuroscience | /articles/nn.2868 | High-accuracy neurite reconstruction for high-... | 2011-02-28 | 2011-05-23 | 2011-07-10 | 84 days | 132 days | . 197 Nature Neuroscience | /articles/nn.2693 | Hippocampal brain-network coordination during ... | 2010-07-12 | 2010-10-06 | 2010-11-21 | 86 days | 132 days | . 198 Nature Neuroscience | /articles/nn.2872 | Owl&#39;s behavior and neural representation predi... | 2010-12-21 | 2011-04-29 | 2011-07-03 | 129 days | 194 days | . 199 rows × 8 columns . We need to put the data into buckets of years and days for calculating the average. . data[&#39;year&#39;] = data.apply(lambda row: row.published.year, axis=1) data[&#39;days&#39;] = data.apply(lambda row: row.timeForAcceptance.days, axis=1) data[&#39;daysp&#39;] = data.apply(lambda row: row.timeForPublishing.days, axis=1) . Let&#39;s plot the data: . plt.figure(figsize=(6, 3), dpi=300) ax=plt.gca() xfmt = md.DateFormatter(&#39;%Y&#39;) ax.xaxis.set_major_formatter(xfmt) years = [parser.parse(str(data.groupby(by=&#39;year&#39;).days.mean().index[d])) for d in range(len(data.groupby(by=&#39;year&#39;)))] years_beginning = [datetime.datetime(y.year, month=1, day=1) for y in years] mean_time = data.groupby(by=&#39;year&#39;).days.mean() std_time = data.groupby(by=&#39;year&#39;).days.std() plt.plot(years_beginning, mean_time, label=&#39;Yearly mean until accepted&#39;, c=&#39;C3&#39;) plt.plot(years_beginning, data.groupby(by=&#39;year&#39;).daysp.mean(), label=&#39;Yearly mean until published&#39;, c=&#39;C0&#39;) plt.legend(fontsize=10) for di in range(len(data)): plt.scatter(data.iloc[di].received, data.iloc[di].days, c=&#39;C3&#39;, s=5, edgecolor=&#39;k&#39;, linewidth=0.5) plt.xlabel(&quot;Time of submission&quot;) plt.ylabel(&quot;Days&quot;) plt.title(&quot;Time for acceptance of Computational nNeuroscience papers in Nature Neuroscience&quot;) plt.savefig(&quot;../images/icon_natureneuroscience.png&quot;); . So, how long? . On average, it took 157.47 days for a paper to be published from the day it was submitted. . This page was last built on 09.12.20 17:28:39 .",
            "url": "https://caglorithm.github.io/notebooks/nature-neuroscience-submission/",
            "relUrl": "/nature-neuroscience-submission/",
            "date": " • Apr 22, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "A gentle introduction to neurolib",
            "content": ". What is neurolib? . In its essence, neurolib is a computational framework for simulating coupled neural mass models written in Python. It helps you to easily load structural brain scan data to construct brain networks where each node is a neural mass representing a single brain area. This network model can be used to simulate whole-brain dynamics. Finally, neurolib allows you to simulate BOLD activity from the underlying neural activity to be able to compare simulations to fMRI brain scan data. You can checkout neurolib on our GitHub page and find a lot of examples there, including more advanced features like parameter exploration and evolutionary optimization. . We have built neurolib because like for many computational neuroscientists, working with neural models is daily business. However, no open-source framework was available to help us implement our own models, run large-scale simulations and handle huge amounts of simulated data efficiently. As it happens so often in research, we ended up writing our own software for our own special case. This is why we decided to join our forces and models to create neurolib, a library that solves these common issues and more. . Other software projects that we&#39;re familiar with like TheVirtualBrain offer a lot of functionality with a useful UI. In neurolib, our goal is to create a hackable framework for coders and focus on the simulation and optimization machinery. We are not planning to add many “utility functions” like plotting data or more than just basic signal processing. In our experience, every researcher has their own workflow and we don’t want to make others rely on our implementations, when they’re usually more than fine using their own processing pipeline with everything that Python has to offer, including matplotlib, numpy, pandas, and scipy. . In this sense, neurolib is primarily a modern research tool and our main goal is to provide an accessible research framework. However, it is built with people in mind who are new to the field and just want to get going. We have made it as easy as possible to setup a simulation or to implement your own model and run your experiments. . We are using neurolib in our daily research as much as we&#39;re also working on the framework itself. In the future, we expect neurolib to help researchers gain better theoretical insights into their neural models, produce more useful results, and enable them to run and manage large, hierarchical, multi-model simulations. . You&#39;re warmly invited to join our development efforts on our GitHub page, report a bug if you find issues, submit a PR with your favorite model that you want to see implemented or just get in touch with us. . A computational neuroscience primer . Let&#39;s start at the beginning. Computational neuroscience is the scientific field in which mathematical tools and theories are used to investigate brain function. One of these tools is network science and the study of dynamical systems theory. Across all relevant scales for studying brain function, scientists have created mathematical models for simulating neuronal systems ranging from highly complex single neuron models which simulate individual chemical processes in the cell up to theories of large networks of neurons that disregard most of the complicated details in order to gain insights into the large-scale behavior of neural systems. . Neural mass models are such mathematical models that help to simulate and understand the behavior of a large number of coupled neurons. Typically, these models make use of the statistical insight that the collective, macroscopic behavior of a large network of randomly connected neurons can be described without having to know the exact dynamics of every individual neuron at every time step. This is much like a statistical physicist would treat a gas where for example the temperature of the gas is an expression of the mean velocity of the gas particles, not the individual velocity of each particle. . . A DTI scan of a human brain with long-range axonal fibers. Animation source . Towards simulating brains . Now that we have an idea about what neural masses are, what are they useful for and how is this related to neurolib? One of the applications of neural mass models in computational neuroscience is in whole-brain modeling, where a coarse-grained simulation of the activity of a large network of brain areas is achieved by combining simulations of neural masses with structural connectivity scans (often referred to as the connectome, an example is shown in the animation above) of the human brain which captures large axonal connections that connect distant brain areas. These models offer an in silico approach (through computational modeling) to investigate the large-scale dynamics of the in vivo brain, such as the appearance and the properties of brain oscillations or the effects of electrical stimulation of certain brain areas. . neurolib allows you to build, simulate, and optimize your own state-of-the-art whole-brain models. To simulate the neural activity of each brain area, the main implementation provides an advanced neural mass mean-field model of spiking adaptive exponential integrate-and-fire neurons (AdEx) called aln. Each brain area is represented by two populations of excitatory and inhibitory neurons. An extensive analysis and validation of the aln model can be found in our paper [1]. . [1] Cakan et al. (2020). Biophysically grounded mean-field models of neural populations under electrical stimulation. PLOS Computational Biology (ArXiv). . The figure below shows a schematic of how a brain network is constructed: . . On the left side of the figure, you can see structural brain scan data with the axonal fiber tractography (Connectome) and a parcellation scheme (AAL2 atlas) that divides the brain into distinct volumes. Below, you can see the Structural connectivity matrix, which captures the coupling strength between each area and is derived from the number of reconstructed axonal fibers from one brain area to another, and the Delay matrix, which captures the signal transmission delay between brain areas and is derived from the length of the fibers. On the right side, you can see a schematic of the aln neural mass model, representing a single brain area with excitatory neurons (orange population, E) and inhibitory neurons (blue population, I) and connections within and between the populations. Combining the structural brain data with the neural model is how we construct a whole-brain model. . The neural mass model . In this notebook we will learn about the basics of neurolib. First, we will create a neural mass model of exponential integrate-and-fire neurons called the aln model, which represents a single brain area. We will learn how to create a Model, set some parameters and run a simulation. We will also see how we can easily access the output of each simulation. Later, we will create a bunch of neural mass models and couple them in a brain graph to simulate a whole-brain model. . aln - the adaptive linear-nonlinear cascade model . The adaptive linear-nonlinear (aln) cascade model is a low-dimensional population model of spiking neural networks. Mathematically, it is a dynamical system of non-linear ordinary differential equations (ODEs). The dynamical variables of the system simulated in the aln model describe the average firing rate and other macroscopic variables of a randomly connected, delay-coupled network of excitatory and inhibitory adaptive exponential integrate-and-fire neurons (AdEx) with non-linear synaptic currents. . Ultimately, the model is a result of various steps of model reduction starting from the Fokker-Planck equation of the AdEx neuron subject to white noise input with different mean $ mu$ and variance $ sigma$. The resulting steady-state firing rates $r$ and the linear response function of the neural population are then stored in a lookup table. When we finally simulate the system, these precomputed quantities serve as the linear filter and the nonlinear firing rate transfer function $r = Phi( mu, sigma)$ in the adaptive linear-nonlinear cascade model. . Using neurolib . Let&#39;s get going after all this reading. neurolib makes it easy to set of your simulation. Below, we demonstrate how you set up a model and interact with its parameters. We will first explore a single node which represents a brain area and get comfortable with the way things work and later set up a whole-brain simulation and simulate fMRI activity. . Simulating a single node . To create a single node, we instantiate the model without any arguments. . # Let&#39;s import the aln model from neurolib.models.aln import ALNModel # Create the model aln = ALNModel() # Each model comes with a set of default parameters which are are a dictionary. # Let&#39;s change the parameter that controls the duration of a simulation to 10s. aln.params[&#39;duration&#39;] = 10.0 * 1000 # For convenience, we could also use: aln.params.duration = 10.0 * 1000 # In the aln model an Ornstein-Uhlenbeck process is simulated in parallel # as the source of input noise fluctuations. Here we can set the variance # of the process. # For more info: https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process # Let&#39;s add some noise. aln.params[&#39;sigma_ou&#39;] = 0.1 # Finally, we run the model aln.run() . Accessing the outputs . Accessing the outputs is straight-forward. Every model&#39;s outputs are stored in the model.outputs attribute. According to the specific name of each of the model&#39;s outputs, they can also be accessed as a key of the Model object, i.e. aln[&#39;rates_exc&#39;]. . Let&#39;s have a look what the outputs of the aln model are called: . aln.outputs.keys() . dict_keys([&#39;t&#39;, &#39;rates_exc&#39;, &#39;rates_inh&#39;]) . As you can see here, the model produces several outputs after executing aln.run(). The first entry t is an array of the simulation time in milliseconds: . aln[&#39;t&#39;] . array([1.0000e-01, 2.0000e-01, 3.0000e-01, ..., 9.9998e+03, 9.9999e+03, 1.0000e+04]) . Let&#39;s have a look, what the excitatory firing rate output rates_exc of the model looks like. If you&#39;re lazy, you can also access most of the key-valued objects in neurolib using a dot.separated syntax: . aln.rates_exc.shape . (1, 100000) . The entries of aln.rates_exc are the excitatory population&#39;s firing rate in time. Every model&#39;s default output, in this case rates_exc, can also be accessed by calling the default output attribute: . aln.output . array([[26.15770656, 24.06801404, 22.22713507, ..., 1.82543728, 1.78704101, 1.75078031]]) . Plotting the output against the simulated time aln.t, we get: . Outputs are also available as an xarray.DataArray: . xr = aln.xr() print(xr.dims) . (&#39;output&#39;, &#39;space&#39;, &#39;time&#39;) . Exploring the state space using bifurcation diagrams . To understand the model better, we should figure out what it does if we change certain model parameters. We have already seen that adding some noise can create these nice irregular oscillations. . One way of characterizing the effects of parameters on a dynamical system is to compute bifurcation diagrams. Bifurcations are sudden and often dramatic changes in a system&#39;s behavior due to a small smooth change of some parameter (the bifurcation parameter). Usually, a bifurcation results in a rapid change of a system&#39;s state such as a transition to a oscillation. In the aln model, as well as in most neural models with excitatory and inhibitory units, the most prominent oscillation is due to the interaction of both populations, often known as an E-I oscillation . One of the most important parameters of the aln model is the external input currents to each subpopulation. The parameter that controls the inputs to the excitatory population is called mue_ext_mean, which is a terrible way of saying &quot;mean input current to the excitatory subpopulation&quot;. . Let&#39;s check the current value of this parameter: . aln.params[&quot;mue_ext_mean&quot;] . 0.4 . Again, we could&#39;ve also used the syntax aln.params.mue_ext_mean as well. . We want to know how our model is behaving under changes of this parameter so it might a good idea to do a quick parameter exploration. For this, we scan through a range of possible values of mue_ext_mean, simulate the model for a bit and record the minimum and the maximum value of the firing rate of the excitatory population rates_exc. We remember all these values and draw a bifurcation diagram in the end. . # initialize the model aln = ALNModel() aln.params[&#39;duration&#39;] = 2.0*1000 # lists that will conatin the results max_outputs = [] min_outputs = [] # these are the different input values that we want to scan inputs = np.linspace(0, 2, 50) # cycle through all input values for mue in inputs: # Note: this has to be a vector since it is input for all nodes # (but we have only one node in this example) aln.params[&#39;mue_ext_mean&#39;] = mue aln.run() # we add the maximum and the minimum of the last second of the # simulation to a list max_outputs.append(np.max(aln.output[0, -int(1000/aln.params[&#39;dt&#39;]):])) min_outputs.append(np.min(aln.output[0, -int(1000/aln.params[&#39;dt&#39;]):])) . Plotting max_outputs and max_inputs against the the inputs gives us the bifurcation diagram of the aln model in the mue_ext_mean-direction of the parameter space: . Text(0, 0.5, &#39;Min / max firing rate [Hz]&#39;) . We can see that at low input values (between 0 and 0.25), there is basically no activity with values of barely above 0 Hz. We call this the down-state. At a certain threshold point though, the lines diverge and an oscillatory state can be observed (between 0.25 and 1.25). Here the activity oscillates between the excitatory and the inhibitory populations. Increasing the input even further leads to another bifurcation, resulting in a diagram where the lines converge again. The oscillation stops and the activity returns to a constant firing rate, now with an increased level than where we started. This is called the up-state. . Whole-brain modeling . Typically, in whole-brain modeling, diffusion tensor imaging (DTI) is used to infer the structural connectivity (the connection strength) between different brain areas. In a DTI scan, the direction of the diffusion of molecules is measured across the whole brain. Using tractography, this information can yield the distribution of axonal fibers in the brain that connect distant brain areas, called the connectome. Together with an atlas that divides the brain into distinct areas, a matrix can be computed that encodes how many fibers go from one area to another, the so-called structural connectivity (SC) matrix. This matrix defines the coupling strengths between brain areas and acts as an adjacency matrix of the brain network. The length of the fibers determine the signal transmission delay between all brain areas. When the structural data is combined with a computational model of the neuronal activity of the cortex, we can create a dynamical model of the whole brain. . The resulting whole-brain model consists of interconnected brain areas, with each brain area having their internal neural dynamics. The neural activity is used to simulate hemodynamic BOLD activity using the Balloon-Windkessel model, which can be compared to empirical fMRI data. The simulated BOLD activity is used to compute correlations of activity between all brain areas, the so called resting state functional connectivity, which can then be fitted to empirical fMRI resting-state data. One such example of simulated brain activity is shown in the animation below. . . Setting up a brain . neurolib comes with example datasets for exploring its functionality. Please be aware that these datasets are not tested and should not be used for your research, only for experimentation with the software. . A dataset for whole-brain modeling can consists of the following parts: . A structural connectivity (SC) matrix capturing the synaptic connection strengths between brain areas, often derived from DTI tractography of the whole brain. The connectome is then typically parcellated in a preferred atlas (for example the AAL2 atlas) and the number of axonal fibers connecting each brain area with every other area is counted. This number serves as a indication of the synaptic coupling strengths between the areas of the brain. | A delay matrix which can be calculated from the average length of the axonal fibers connecting each brain area with another. | A set of functional data that can act as a target for model optimization. Resting-state fMRI BOLD activity offers an easy and fairly unbiased way for calibrating whole-brain models. Usually, not the BOLD timeseries itself is used to evaluate and fit the model, but the area-wise correlation matrix, called functional connectivity (FC) matrix. This matrix measures how well the activation and deactivation of brain areas is synchronized in time. | . We can load a Dataset by passing the name of it in the constructor. In this case, we load processed data from the Human Connectome Project: . from neurolib.utils.loadData import Dataset ds = Dataset(&quot;hcp&quot;) . The hcp dataset comes with data from a few subjects. The objects ds.Cmat and ds.Dmat represent the structural connectivity and the fiber length matrix averaged over all subjects of the dataset. The individual datasets can be accessed through ds.Cmats, ds.Dmats. Functional data per subject can be found in ds.BOLDs and ds.FCs. The latter contains the functional connectivity matrices (computed from the BOLD timeseries ds.BOLDs) per subject. . The connectivity matrix is a numpy.array with it&#39;s entries representing the coupling strength between all brain areas. Its dimensions are N x N, with N being the number of brain areas of the chosen atlas: . ds.Cmat.shape . (80, 80) . We now create the aln model with a structural connectivity matrix and a delay matrix. In order to achieve a good fit of the BOLD activity to the empirical data, the model has to run for quite a while. A a rule of thumb, a simulation of resting-state BOLD activity should not be shorter than 3 minutes and preferably longer than 5 minutes real time. If the empirical recordings are for example 10 minutes long, ideally, a simulation of 10 minutes would be used to compare the output of the model to the resting state recording. . # We load the model, but now with the structural dataset aln = ALNModel(Cmat = ds.Cmat, Dmat = ds.Dmat) # Let&#39;s run the simulation for a few minutes aln.params[&#39;duration&#39;] = 3*60*1000 . We did some optimization of the brain network model before by fitted it to the resting-state fMRI data of the dataset. The following set of parameters was found to produce interesting whole-brain dynamics that approximates the empirical functional connectivity (FC) data well. Specifically, the mean input of the excitatory and the inhibitory population are chosen to be close to the E-I limit cycle. . aln.params[&#39;mue_ext_mean&#39;] = 1.57 aln.params[&#39;mui_ext_mean&#39;] = 1.6 # We set an appropriate level of noise aln.params[&#39;sigma_ou&#39;] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. aln.params[&#39;b&#39;] = 5.0 . Let&#39;s have a look what the data looks like. We can access the data of each model by calling its internal attributes. Here, we plot the structural connectivity matrix by calling aln.params[&#39;Cmat&#39;] and fiber length matrix by calling aln.params[&#39;lengthMat&#39;]. Of course, we can also access the dataset using the Dataset object itself. For example the functional connectivity matrices of the BOLD timeseries in the datasets are given as list with ds.FCs. . Run the model . We run the model with bold simulation by using bold=True. This simulates the Balloon-Windkessel BOLD model in parallel to the neural population model in order to estimate the blood oxygen levels of the underlying neural activity. The output of the bold model can be used to compare the simulated data to empirical fMRI data (resting-state fMRI for example). . To save (a lot of) RAM, we can run the simulation in chunkwise mode. In this mode, the model will be simulated for a length of chunksize steps (not time in ms, but actual integration steps!), and the output of that chunk will be used to automatically reinitialize the model with the appropriate initial conditions. This allows for a serial continuation of the model without having to store all the data in memory and is particularly useful for very long and many parallel simulations. . aln.run(chunkwise=True, chunksize = 100000, bold=True) . Analyzing simulation results . The outputs of the model can be accessed using the attribute model.outputs . aln.outputs.keys() . dict_keys([&#39;t&#39;, &#39;rates_exc&#39;, &#39;rates_inh&#39;, &#39;BOLD&#39;]) . For convenience, they can also be accessed directly using attributes of the model with the outputs name, like aln.rates_exc. The outputs are also available as xarray.DataArrays as aln.xr(). . The since we used bold=True to simulate BOLD, we can also access aln.BOLD.BOLD for the actual BOLD activity, and aln.BOLD.t for the time steps of the BOLD simulation (which are downsampled to 0.5 Hz by default). . Plot the simulated activity . Let&#39;s have a look at the simulated BOLD activity. We plot the simulated functional connectivity (FC) matrix that captures the correlations of the BOLD signal in each brain area, and the BOLD time series itself. . This looks nice! The simulated FC already looks fairly similar to the empirical FC data from our hcp dataset shown earlier. We have also access to the underlying neuronal activity, that caused this BOLD signal. Since we have used model.run(chunkwise=True) to save memory, neurolib didn&#39;t save the full timeseries but only the last chunk: . We can see in the timeseries above that the activity in the different brain areas (each represented by a different color) tends to synchronize and create irregular bursts of global activity resulting in slow brain oscillations. . Correlation of simulated FC to empirical FC . We can compute the element-wise Pearson correlation of the simulated and empirical BOLD functional connectivity matrices to estimate how well the model captures the inter-areal resting-state BOLD correlations from fMRI scans. As a rule of thumb, a correlation value of 0.5 and above is considered good. We use the built-in functions func.fc() to calculate the functional connectivity of a n-dimensional timeseries and func.matrix_correlation() to compute the correlation between simulated and empirical data. . scores = [func.matrix_correlation(func.fc(aln.BOLD.BOLD[:, 5:]), fcemp) for fcemp in ds.FCs] print(&quot;Correlation per subject:&quot;, [f&quot;{s:.2}&quot; for s in scores]) print(f&quot;Mean FC/FC correlation: {np.mean(scores):.2}&quot;) . Correlation per subject: [&#39;0.5&#39;, &#39;0.56&#39;, &#39;0.6&#39;, &#39;0.49&#39;, &#39;0.51&#39;, &#39;0.48&#39;, &#39;0.62&#39;] Mean FC/FC correlation: 0.54 . Since this notebook is automatically generated, I hope the result is pretty good :) . Acknowledgments . neurolib is built on other amazing open source projects: . pypet - Python parameter exploration toolbox | deap - Distributed Evolutionary Algorithms in Python | numpy - The fundamental package for scientific computing with Python | numba - NumPy aware dynamic Python compiler using LLVM | Jupyter - Jupyter Interactive Notebook | fastpages - An easy to use blogging platform | binder - Reproducible executable environments | Bob Holzer is the author of the the brain network visual asset of this post&#39;s title image which is released under the Creative Commons license | . Last build 15.04.20 19:44:08 .",
            "url": "https://caglorithm.github.io/notebooks/neurolib-intro/",
            "relUrl": "/neurolib-intro/",
            "date": " • Apr 10, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "COVID-19 - Confirmed Cases vs. Deaths",
            "content": "This page was last built on 20.06.21 02:02:19 . Estimated time of infection vs. confirmed infections . Following the ideas from Tomas Pueyo&#39;s Medium post &quot;Coronavirus: Why You Must Act Now&quot; [1], we assume the average time from infection to death at 23 days [2]. The data is pulled from the COVID-19 Data Repository by Johns Hopkins CSSE [3] every hour. Countries with a minimnum of 1000 confirmed cases and 40 confirmed deaths are included in this analysis. . The time from infection to death is equal to the incubation period plus the time from symptoms to death. This is used to estimate the time of the infections that lead to the observed deaths. We take the last fatality rate per country (total_cases/total_deaths) to estimate the number of infections that are responsible for the observed deaths. . In the figures below, you can observe successive waves of infections (dashed), detections (black) and deaths (red) for each country. The upper panel shows the absolute number of events. The dashed lines show the estimated number of infections. The lower panel shows the normalized number of events. Here the temporal delay between the waves and the relative change between each other can be observed. . [1] https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca . [2] https://github.com/midas-network/COVID-19/tree/master/parameter_estimates/2019_novel_coronavirus . [3] https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series . US . Brazil . India . Mexico . Peru . United Kingdom . Italy . Russia . France . Colombia . Germany . Argentina . Iran . Spain . Poland . South Africa . Ukraine . Indonesia . Turkey . Romania . Chile . Czechia . Hungary . Canada . Belgium . Philippines . Pakistan . Ecuador . Netherlands . Bulgaria . Portugal . Iraq . Bolivia . Egypt . Sweden . Japan . Tunisia . Bangladesh . Greece . Slovakia . Paraguay . Switzerland . Austria . Jordan . Bosnia and Herzegovina . Morocco . Nepal . Guatemala . Croatia . Lebanon . Saudi Arabia . Serbia . Honduras . Panama . Israel . Moldova . North Macedonia . Uruguay . Georgia . Ireland . Azerbaijan . China . Armenia . Costa Rica . Slovenia . Lithuania . Ethiopia . Malaysia . Afghanistan . Dominican Republic . Algeria . West Bank and Gaza . Kazakhstan . Kenya . Burma . Libya . Belarus . Venezuela . Sudan . Oman . Denmark . Latvia . Sri Lanka . Albania . El Salvador . Kosovo . Nigeria . South Korea . Kyrgyzstan . Kuwait . Syria . United Arab Emirates . Zimbabwe . Montenegro . Thailand . Zambia . Cameroon . Bahrain . Estonia . Malawi . Senegal . Cuba . Namibia . Jamaica . Finland . Botswana . Australia . Madagascar . Congo (Kinshasa) . Angola . Mozambique . Luxembourg . Ghana . Norway . Somalia . Uzbekistan . Trinidad and Tobago . Eswatini . Uganda . Qatar . Mali . Taiwan* . Mauritania . Suriname . Guyana . Mongolia . Malta . Cambodia . Rwanda . Cyprus . Haiti . Belize . Lesotho . Cote d&#39;Ivoire . Cabo Verde . Bahamas . Hong Kong . Maldives . Burkina Faso . Guinea . Papua New Guinea . Congo (Brazzaville) . Gabon . Djibouti . Andorra . Togo . South Sudan . Ahead of the curve . Some countries start testing the population earlier in the outbreak than others. The time delay between the wave of deaths and the wave of confirmed cases is indicative for how early a country is detecting new cases ahead of the increase of deaths. Earlier detection means a better chances for successful isolation of an infected person and treatment of the desease. . We measure the distance of the maximum of cumulative deaths and new deaths to the number of infections to estimate the progression of the infection across countries. . If, in the early phase of the infection wave, the number of deaths rises faster than the number of confirmed cases, the distance drops, indicating that . A comparison of countries with respect to their mean time for reponse is presented below. . To determine the above values, we plot the number of confirmed cases (solid black lines) and the number of deaths (dashed black lines). From this, we measure the distance of the day of maximum deaths (dashed red lines) to the day of confirmed cases at this y-value. . The distance is indicative for how fast the humber of confirmed cases increases comapred to the increase of the number of deaths. . US . Brazil . India . Mexico . Peru . United Kingdom . Italy . Russia . France . Colombia . Germany . Argentina . Iran . Spain . Poland . South Africa . Ukraine . Indonesia . Turkey . Romania . Chile . Czechia . Hungary . Canada . Belgium . Philippines . Pakistan . Ecuador . Netherlands . Bulgaria . Portugal . Iraq . Bolivia . Egypt . Sweden . Japan . Tunisia . Bangladesh . Greece . Slovakia . Paraguay . Switzerland . Austria . Jordan . Bosnia and Herzegovina . Morocco . Nepal . Guatemala . Croatia . Lebanon . Saudi Arabia . Serbia . Honduras . Panama . Israel . Moldova . North Macedonia . Uruguay . Georgia . Ireland . Azerbaijan . China . Armenia . Costa Rica . Slovenia . Lithuania . Ethiopia . Malaysia . Afghanistan . Dominican Republic . Algeria . West Bank and Gaza . Kazakhstan . Kenya . Burma . Libya . Belarus . Venezuela . Sudan . Oman . Denmark . Latvia . Sri Lanka . Albania . El Salvador . Kosovo . Nigeria . South Korea . Kyrgyzstan . Kuwait . Syria . United Arab Emirates . Zimbabwe . Montenegro . Thailand . Zambia . Cameroon . Bahrain . Estonia . Malawi . Senegal . Cuba . Namibia . Jamaica . Finland . Botswana . Australia . Madagascar . Congo (Kinshasa) . Angola . Mozambique . Luxembourg . Ghana . Norway . Somalia . Uzbekistan . Trinidad and Tobago . Eswatini . Uganda . Qatar . Mali . Taiwan* . Mauritania . Suriname . Guyana . Mongolia . Malta . Cambodia . Rwanda . Cyprus . Haiti . Belize . Lesotho . Cote d&#39;Ivoire . Cabo Verde . Bahamas . Hong Kong . Maldives . Burkina Faso . Guinea . Papua New Guinea . Congo (Brazzaville) . Gabon . Djibouti . Andorra . Togo . South Sudan .",
            "url": "https://caglorithm.github.io/notebooks/covid-cases-to-deaths/",
            "relUrl": "/covid-cases-to-deaths/",
            "date": " • Mar 21, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hey! . During day, I’m a theoretical physicist in computational neuroscience, trying to understand the brain as a dynamical system at the Neural Information Processing Group at Technische Universität Berlin. . I’m also building a brain simulation framework called neurolib which you can check out here. . During night, I usually sleep. . You can find more information about my projects on my GitHub profile page. . I am only able to run this blog because of the incredible achievements of the global open source community providing amazing free software to the world. Please give back whenever you can. . You can reach me via email or via the handle @caglorithm on Telegram and Twitter. . Thanks for visiting! 1 . This blog is powered by fastpages. &#8617; . |",
          "url": "https://caglorithm.github.io/notebooks/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://caglorithm.github.io/notebooks/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}